---
---

@string{aps = {American Physical Society,}}

@inproceedings{ren2021empirical,
  title={Empirical evaluation of smart contract testing: What is the best choice?},
  author={Ren, Meng and Yin, Zijing and Ma, Fuchen and Xu, Zhenyang and Jiang, Yu and Sun, Chengnian and Li, Huizhong and Cai, Yan},
  booktitle={Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages={566--579},
  abstract={Security of smart contracts has attracted increasing attention in recent years. Many researchers have devoted themselves to devising testing tools for vulnerability detection. Each published tool has demonstrated its effectiveness through a series of evaluations on their own experimental scenarios. However, the inconsistency of evaluation settings such as different data sets or performance metrics, may result in biased conclusion. In this paper, based on an empirical evaluation of widely used smart contract testing tools, we propose a unified standard to eliminate the bias in the assessment process. First, we collect 46,186 source-available smart contracts from four influential organizations. This comprehensive dataset is open to the public and involves different code characteristics, vulnerability patterns and application scenarios. Then we propose a 4-step evaluation process and summarize the difference among relevant work in these steps. We use nine representative tools to carry out extensive experiments. The results demonstrate that different choices of experimental settings could significantly affect tool performance and lead to misleading or even opposite conclusions. Finally, we generalize some problems of existing testing tools, and propose some possible directions for further improvement.},
  html={https://dl.acm.org/doi/10.1145/3460319.3464837},
  bibtex_show={true},
  dimensions={true},
  doi = {10.1145/3460319.3464837},
  publisher = {Association for Computing Machinery},
  year={2021}
}

@article{ma2021pluto,
  title={Pluto: Exposing vulnerabilities in inter-contract scenarios},
  author={Ma, Fuchen and Xu, Zhenyang and Ren, Meng and Yin, Zijing and Chen, Yuanliang and Qiao, Lei and Gu, Bin and Li, Huizhong and Jiang, Yu and Sun, Jiaguang},
  journal={IEEE Transactions on Software Engineering},
  volume={48},
  number={11},
  pages={4380--4396},
  year={2021},
  abstract={Attacks on smart contracts have caused considerable losses to digital assets. Many techniques based on symbolic execution, fuzzing, and static analysis are used to detect contract vulnerabilities. Most of the current analyzers only consider vulnerability detection intra-contract scenarios. However, Ethereum contracts usually interact with others by calling their functions. A bug hidden in a path that depends on information from external contract calls is defined as an inter-contract vulnerability. Failure to deal with this kind of bug can result in potential false negatives and false positives. In this work, we propose Pluto, which supports vulnerability detection in inter-contract scenarios. It first builds an Inter-contract Control Flow Graph (ICFG) to extract semantic information among contract calls. Afterward, it symbolically explores the ICFG and deduces Inter-Contract Path Constraints (ICPC) to check the reachability of execution paths more accurately. Finally, Pluto detects whether there is a vulnerability based on some predefined rules. For evaluation, we compare Pluto with five state-of-the-art tools, including Oyente, Mythril, Securify, ILF, and Clairvoyance on a labeled benchmark and 39,443 real-world Ethereum smart contracts. The result shows that other tools can only detect 10% of the inter-contract vulnerabilities, while Pluto can detect 80% of them on the labeled dataset. Beyond that, Pluto has detected 451 confirmed vulnerabilities on real-world contracts, including 36 vulnerabilities in inter-contract scenarios. Two bugs have been assigned with unique CVE identifiers by the US National Vulnerability Database (NVD). On average, Pluto costs 16.9 seconds to analyze a contract, which is as fast as the state-of-the-art tools.},
  html={https://ieeexplore.ieee.org/document/9562567},
  doi={10.1109/TSE.2021.3117966},
  bibtex_show={true},
  dimensions={true},
  publisher={IEEE}
}

@inproceedings{wang2023compilation,
  author = {Wang, Theodore Luo and Tian, Yongqiang and Dong, Yiwen and Xu, Zhenyang and Sun, Chengnian},
  title = {Compilation Consistency Modulo Debug Information},
  year = {2023},
  isbn = {9781450399166},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  html = {https://doi.org/10.1145/3575693.3575740},
  doi = {10.1145/3575693.3575740},
  abstract = {Compilation Consistency Modulo Debug Information (CCMD) is an essential compiler property that a production compiler should support: the compiler should emit the same machine code regardless of enabling debug information. CCMD is vital to developers’ experiences with debugging a production binary containing no debug information. To debug such a binary, developers need build another binary with the same compiler flags and enable debug information. Without CCMD, the machine code in the latter binary will be different, which can confuse the debugger, hide the bug, or even cause a miscompilation (as GCC once did with the Linux Kernel). This paper is the first to introduce to the research community the validation of CCMD, a new research problem that has been overlooked for decades despite its importance. More importantly, we propose the first testing technique Dfusor to automatically validate CCMD for C compilers. At the high level, given a compilable program P as a seed, Dfusor automatically generates compilable program variants via multiple effective program transformations. Such variants can cause a compiler to emit more debug information than it would when compiling P, thus exercising more code paths in the compiler and increasing the chance to find CCMD bugs. Our extensive evaluations of Dfusor demonstrate that Dfusor can produce variants that exhibit significant increases in the quantity and complexity of the emitted debug information, and thus has found new, real bugs in GCC and LLVM. With a sample of 100 variants derived from distinct seed programs, Dfusor introduces 214% more debug information entries and 36% more distinct debug information entries in the variants than the seeds, and improves the code coverage of GCC and Clang by up to 6.00% and 6.82%. More importantly, Dfusor has found CCMD bugs; within 10 months of development and intermittent testing, Dfusor has found 23 bugs (9 in GCC and 14 in Clang), with 3 confirmed and 18 fixed.},
  booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
  pages = {146–158},
  numpages = {13},
  keywords = {Compiler Testing, Debug Information},
  location = {Vancouver, BC, Canada},
  bibtex_show={true},
  dimensions={true},
  series = {ASPLOS 2023}
}

@article{xu2023pushing,
  author = {Xu, Zhenyang and Tian, Yongqiang and Zhang, Mengxiao and Zhao, Gaosen and Jiang, Yu and Sun, Chengnian},
  title = {Pushing the Limit of 1-Minimality of Language-Agnostic Program Reduction},
  year = {2023},
  issue_date = {April 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {7},
  number = {OOPSLA1},
  html = {https://doi.org/10.1145/3586049},
  doi = {10.1145/3586049},
  abstract = {Program reduction has demonstrated its usefulness in facilitating debugging language implementations in practice, by minimizing bug-triggering programs. There are two categories of program reducers: language-agnostic program reducers (AGRs) and language-specific program reducers (SPRs). AGRs, such as HDD and Perses, are generally applicable to various languages; SPRs are specifically designed for one language with meticulous thoughts and significant engineering efforts, e.g., C-Reduce for reducing C/C++ programs. Program reduction is an NP-complete problem: finding the globally minimal program is usually infeasible. Thus all existing program reducers resort to producing 1-minimal results, a special type of local minima. However, 1-minimality can still be large and contain excessive bug-irrelevant program elements. This is especially the case for AGR-produced results because of the generic reduction algorithms used in AGRs. An SPR often yields smaller results than AGRs for the language for which the SPR has customized reduction algorithms. But SPRs are not language-agnostic, and implementing a new SPR for a different language requires significant engineering efforts. This paper proposes Vulcan, a language-agnostic framework to further minimize AGRs-produced results by exploiting the formal syntax of the language to perform aggressive program transformations, in hope of creating reduction opportunities for other reduction algorithms to progress or even directly deleting bugirrelevant elements from the results. Our key insights are two-fold. First, the program transformations in all existing program reducers including SPRs are not diverse enough, which traps these program reducers early in 1-minimality. Second, compared with the original program, the results of AGRs are much smaller, and time-wise it is affordable to perform diverse program transformations that change programs but do not necessarily reduce the sizes of the programs directly. Within the Vulcan framework, we proposed three simple examples of fine-grained program transformations to demonstrate that Vulcan can indeed further push the 1-minimality of AGRs. By performing these program transformations, a 1-minimal program might become a non-1-minimal one that can be further reduced later. Our extensive evaluations on multilingual benchmarks including C, Rust and SMT-LIBv2 programs strongly demonstrate the effectiveness and generality of Vulcan. Vulcan outperforms the state-of-the-art language-agnostic program reducer Perses in size in all benchmarks: On average, the result of Vulcan contains 33.55%, 21.61%, and 31.34% fewer tokens than that of Perses on C, Rust, and SMT-LIBv2 subjects respectively. Vulcan can produce even smaller results if more reduction time is allocated. Moreover, for the C programs that are reduced by C-Reduce, Vulcan is even able to further minimize them by 10.07%.},
  journal = {Proc. ACM Program. Lang.},
  month = {apr},
  articleno = {97},
  numpages = {29},
  bibtex_show={true},
  dimensions={true},
  keywords = {Test Input Minimization, Program Reduction, Automated Debugging}
}

@inproceedings{tian2023revisiting,
  author={Tian, Yongqiang and Xu, Zhenyang and Dong, Yiwen and Sun, Chengnian and Cheung, Shing-Chi},
  title={Revisiting the Evaluation of Deep Learning-Based Compiler Testing},
  booktitle={The 32nd International Joint Conference on Artificial Intelligence (IJCAI-23), to appear},
  year={2023}
}

@inproceedings{zhang2023ppr,
  author={Zhang, Mengxiao and Xu, Zhenyang and Tian, Yongqiang and Jiang, Yu and Sun, Chengnian},
  title={PPR: Pairwise Program Reduction},
  booktitle={ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, to appear},
  year={2023}
}
